{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle\n",
    "from getpass import getuser\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (classification_report,precision_score,recall_score,roc_auc_score,f1_score,confusion_matrix)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import (Bucketizer,QuantileDiscretizer,VectorAssembler,StandardScaler,OneHotEncoder,StringIndexer)\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.classification import GBTClassifier,GBTClassificationModel\n",
    "from pyspark.mllib.evaluation import (BinaryClassificationMetrics,MulticlassMetrics)\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_address = 'hdfs:///user/{}/acc_final/final_models/'.format(getuser())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-religion",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df= spark.sql('select * from feature_table_data')\n",
    "train_df = spark.read.parquet('file_path')\n",
    "train_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-andrew",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data_df, serialized_objects=True, prediction=True):\n",
    "    \"\"\"\n",
    "    preprocess the dataframe for model training and prediction\n",
    "    :param data_df: dataframe to be preprocessed\n",
    "    :param serialized_objects: dictionary to impute null values during prediction\n",
    "    :param prediction: flag for training or prediction\n",
    "    :return : preprocessed dataframe\n",
    "    \"\"\"\n",
    "    if prediction:\n",
    "        max_recency_acc_dig = serialized_objects['max_recency_acc_dig']\n",
    "        max_recency_dig_2yr = serialized_objects['max_recency_dig_2yr']\n",
    "        max_acc_recency_mf  = serialized_objects['max_acc_recency_mf']\n",
    "    else:\n",
    "        max_recency_acc_dig = data_df.approxQuantile('recency_acc_dig', [1.0], 0.00001)[0]\n",
    "        max_recency_dig_2yr = data_df.approxQuantile('recency_dig_2yr', [1.0], 0.00001)[0]\n",
    "        max_acc_recency_mf  = data_df.approxQuantile('acc_recency_mf', [1.0], 0.00001)[0]\n",
    "        \n",
    "    for i in data_df.columns:\n",
    "        data_df = data_df.withColumnRenamed(i, i.lower())\n",
    "        \n",
    "    data_df = data_df.withColumn('acc_flag', F.when(F.col('acc_flag').isNull(),0.0).otherwise(F.col('acc_flag')))\n",
    "    \n",
    "    data_df = data_df.na.fill({\n",
    "        'recency_acc_dig': max_recency_acc_dig,\n",
    "        'recency_dig_2yr': max_recency_dig_2yr,\n",
    "        'acc_recency_mf' : max_acc_recency_mf\n",
    "    })\n",
    "    \n",
    "    freq_acc_upg_2yrs_split = [-float(\"inf\"),0,1,2, float(\"inf\")]\n",
    "    bucketizer_freq_acc_upg_2yrs_split = Bucketizer(splits=freq_acc_upg_2yrs_split, inputCol=\"freq_acc_upg_acc_2yrs\",\n",
    "                                                   outputCol=\"freq_acc_upg_acc_2yrs_bkt\")\n",
    "    data_df = bucketizer_freq_acc_upg_2yrs_split.setHandleInvalid(\"keep\").transform(data_df)\n",
    "    \n",
    "    tot_purchase_split = [-float(\"inf\"),0,1,2,3, float(\"inf\")]\n",
    "    bucketizer_tot_purchase = Bucketizer(splits=tot_purchase_split, inputCol=\"tot_accsry_purchse\",\n",
    "                                        outputCol=\"tot_accsry_purchse_bkt\")\n",
    "    data_df = bucketizer_tot_purchase.setHandleInvalid(\"keep\").transform(data_df)\n",
    "    \n",
    "    del_cols_new = ['freq_acc_upg_acc_2yrs','tot_accsry_purchse']\n",
    "    data_df = data_df.drop(*del_cols_new)\n",
    "    \n",
    "    return data_df, max_recency_acc_dig, max_recency_dig_2yr, max_acc_recency_mf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-archives",
   "metadata": {},
   "source": [
    "# Save Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_objects(pipelineModel, max_recency_acc_dig, max_recency_dig_2yr, max_acc_recency_mf,\n",
    "                num_cols, cat_cols, bin_cols):\n",
    "    \"\"\"\n",
    "    save object to impute null values and model files\n",
    "    :param pipelineModel: model object,\n",
    "    :param max_recency_acc_dig,max_recency_dig_2yr,max_acc_recency_mf: max values,\n",
    "    :param num_cols: numeric columns list,\n",
    "    :param cat_cols: categorical columns list,\n",
    "    :param bin_cols: ordinal categorical columns list,\n",
    "    :return: object file will be saved and return nothing\n",
    "    \"\"\"\n",
    "    # storing trained pipeline\n",
    "    pipelineModel.write().overwrite().save(files_address + 'pipelineModel.file')\n",
    "    \n",
    "    # storing saved Median values\n",
    "    serialized_objects = {}\n",
    "    serialized_objects['num_cols'] = num_cols\n",
    "    serialized_objects['cat_cols'] = cat_cols\n",
    "    serialized_objects['bin_cols'] = bin_cols\n",
    "    serialized_objects['max_recency_acc_dig'] = max_recency_acc_dig\n",
    "    serialized_objects['max_recency_dig_2yr'] = max_recency_dig_2yr\n",
    "    serialized_objects['max_acc_recency_mf']  = max_acc_recency_mf\n",
    "    serialized_objects_pickle = pickle.dumps(serialized_objects)\n",
    "    serialized_objects_file = tf.io.gfile.GFile(files_address + 'pipelineModel_obj.file', 'wb')\n",
    "    serialized_objects_file.write(serialized_objects_pickle)\n",
    "    serialized_objects_file.close()\n",
    "    print('Trained Objects Successfully Stored at :', files_address)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-alberta",
   "metadata": {},
   "source": [
    "# Load Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_objects():\n",
    "    \"\"\"\n",
    "    load pickle files from the stored path\n",
    "    :param: no parameters needed,\n",
    "    :return: model and imputation dict objects\n",
    "    \"\"\"\n",
    "    # Loading trained pipeline\n",
    "    pipeline_model = PipelineModel.load(files_address + 'pipelineModel.file')\n",
    "    \n",
    "    # Load saved Median values\n",
    "    serialized_objects_file = tf.io.gfile.GFile(files_address + 'pipelineModel_obj.file', 'rb')\n",
    "    serialized_objects = pickle.load(serialized_objects_file)\n",
    "    serialized_objects_file.close()\n",
    "    print('Required objects loaded from :', files_address)\n",
    "    return pipeline_model, serialized_objects\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-matter",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sampled_df, feat_cat, feat_num, feat_bin):\n",
    "    \"\"\"\n",
    "    pipeline creation and model training\n",
    "    :param sampled_df: training_dataset,\n",
    "    :param feat_cat: categorical feature list,\n",
    "    :param feat_num: numerical feature list,\n",
    "    :param feat_bin: ordinal categorical feature list,\n",
    "    :return: trained model\n",
    "    \"\"\"\n",
    "    #Vector for numerical features\n",
    "    vector_assembler_NumVars = VectorAssembler(inputCols=feat_num, outputCol='num_features_all')\n",
    "    \n",
    "    #Indexing & Other stuff\n",
    "    indexers_Cat = [StringIndexer(inputCol=tc, outputCol=\"{0}_index\".format(tc)).setHandleInvalid('keep') for tc in\n",
    "                   feat_cat]\n",
    "    assembler_Cat = VectorAssembler(inputCols=[ict.getOutputCol() for ict in indexers_Cat], outputCol='cat_features')\n",
    "    # Bin Assembler\n",
    "    input_feat = [col for col in feat_bin] + ['num_features_all']\n",
    "    assembler_bin = VectorAssembler(inputCols=input_feat, outputCol='bin_features')\n",
    "    \n",
    "    #All features into vector assembler\n",
    "    assembler = VectorAssembler(inputCols = ['cat_features', 'bin_features'], outputCol='features')\n",
    "    \n",
    "    #Sampling training data\n",
    "    train_df = sampled_df\n",
    "    \n",
    "    #Model building\n",
    "    label = 'acc_flag'\n",
    "    features = 'features'\n",
    "    depth = 4\n",
    "    maxIter = 50\n",
    "    minInfoGain = 0.0\n",
    "    checkpointInterval = 12\n",
    "    lossType = 'logistic'\n",
    "    \n",
    "    model = GBTClassifier(labelCol=label,\n",
    "                         featuresCol=features,\n",
    "                         maxDepth = depth,\n",
    "                         maxIter = maxIter,\n",
    "                         minInfoGain = minInfoGain,\n",
    "                         checkpointInterval = checkpointInterval,\n",
    "                         lossType = lossType,\n",
    "                         seed = 1)\n",
    "    preprocessing_stages = [vector_assembler_NumVars] + indexers_Cat + [assembler_Cat] + [assembler_bin] + [assembler]\n",
    "    stages = preprocessing_stages + [model]\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    pipelineModel = pipeline.fit(train_df)\n",
    "    train_scored_df = pipelineModel.transform(train_df)\n",
    "    \n",
    "    df_train = train_scored_df.select(['probability', 'prediction', 'acc_flag', 'features']).toPandas()\n",
    "    \n",
    "    print('Training Summary')\n",
    "    print('AUC on train set: ',roc_auc_score(df_train['acc_flag'], df_train['prediction']))\n",
    "    print(classification_report(df_train['acc_flag'], df_train['prediction']))\n",
    "    \n",
    "    return pipelineModel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(df):\n",
    "    \"\"\"\n",
    "    Sampling the train data and save the model object file\n",
    "    :param df: dataframe to be sampled and trained\n",
    "    :return: saves the model object and returns nothing\n",
    "    \"\"\"\n",
    "    df,max_recency_acc_dig, max_recency_dig_2yr, max_acc_recency_mf = preprocessing(df, prediction = False)\n",
    "    #Over sampling the training data\n",
    "    target = 'acc_flag'\n",
    "    zero = df.where(col(target) == 0)\n",
    "    one  = df.where(col(target) == 1)\n",
    "    ratio = float(zero.count() / one.count())\n",
    "    tr = one.sample(True, ratio, 42)\n",
    "    sampled_df = tr.union(zero)\n",
    "    \n",
    "    cat_cols = ['categorical_columns']\n",
    "    num_cols = ['numerical_col1', 'numerical_col2', 'all_num_cols']\n",
    "    bin_cols = ['binned_columns']\n",
    "    \n",
    "    print('Sampling Data details:')\n",
    "    print('Number of Records :', sampled_df.count())\n",
    "    print('Number of features:', len(sampled_df.columns))\n",
    "    print('Target Distribution :')\n",
    "    \n",
    "    sampled_df.groupBy('acc_flag').count().withColumnRenamed('count','cnt_per_group') \\\n",
    "         .withColumn('% of_total_count',(F.col('cnt_per_group') / sampled_df.count()) * 100).show()\n",
    "    \n",
    "    pipelineModel = train_model(sampled_df, cat_cols, num_cols, bin_cols)\n",
    "    \n",
    "    save_objects(pipelineModel, max_recency_acc_dig, max_recency_dig_2yr, max_acc_recency_mf,\n",
    "                 num_cols, cat_cols, bin_cols )  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-christianity",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(df):\n",
    "    \"\"\"\n",
    "    preprocess the data and score the model\n",
    "    :param df: dataframe to be scored\n",
    "    :return: scored dataframe and model object used for scoring\n",
    "    \"\"\"\n",
    "    pipeline_model, serialized_objects = load_objects()\n",
    "    df, _, _, _ = preprocessing(df, serialized_objects)\n",
    "    \n",
    "    print('Data Distribution:')\n",
    "    print('Number of Records :', df.count())\n",
    "    print('Number of Features :', len(df.columns))\n",
    "    \n",
    "    print('Target Distribution :')\n",
    "    df.groupBy('acc_flag').count().withColumnRenamed('count','cnt_per_group') \\\n",
    "         .withColumn('% of_total_count',(F.col('cnt_per_group') / df.count()) * 100).show()\n",
    "    \n",
    "    df_pred = pipeline_model.transform(df)\n",
    "    df_test = df_pred.select(['probability', 'prediction', 'acc_flag', 'features']).toPandas()\n",
    "    print('Testing Summary')\n",
    "    print('AUC on test set: ',roc_auc_score(df_test['acc_flag'], df_test['prediction']))\n",
    "    print(classification_report(df_test['acc_flag'], df_test['prediction']))\n",
    "    return df_pred, pipeline_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.read.parquet('file path')\n",
    "test_scored_df, model = prediction(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-membership",
   "metadata": {},
   "source": [
    "# Lift for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstelement = udf(lambda v:float(v[0]),FloatType())\n",
    "secondelement = udf(lambda v:float(v[1]),FloatType())\n",
    "\n",
    "def lift_cal(df_predictions_gbt):\n",
    "    total = df_predictions_gbt.count()\n",
    "    df_predictions_gbt = df_predictions_gbt.withColumn('prob_1', secondelement('probability'))\n",
    "    qds = QuantileDiscretizer(numBuckets=10, inputCol='prob_1', outputCol = 'Decile', relativeError = 0.0001, handleInvalid='error')\n",
    "    bucketizer = qds.fit(df_predictions_gbt)\n",
    "    df_predictions_dec = bucketizer.setHandleInvalid('skip').transform(df_predictions_gbt)\n",
    "    df_predictions_dec = df_predictions_dec.groupBy('Decile').agg(F.sum('acc_flag').alias('Buyer'),F.count('acc_flag').alias('decile_count'))\n",
    "    avg = df_predictions_dec.agg(F.avg('Buyer')).collect()[0][0]\n",
    "    df_predictions_dec = df_predictions_dec.withColumn('Lift', F.col('Buyer')/F.lit(avg))\n",
    "    df_predictions_dec = df_predictions_dec.withColumn('Base', F.lit(total))\n",
    "    return df_predictions_dec,avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dec_df, avg_val = lift_cal(test_scored_df)\n",
    "test_dec_df.orderBy(F.col('Decile').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-marijuana",
   "metadata": {},
   "source": [
    "# Train Metrics without sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scored, model = prediction(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
